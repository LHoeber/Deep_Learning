{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#preliminary setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "%pip install -r requirements.txt\n",
    "\n",
    "#Fetching the data\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# set seeds for reproducibility\n",
    "random_seed = 302\n",
    "torch.manual_seed(302); np.random.seed(302)\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=random_seed)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.1, random_state=random_seed, )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#a.) Investigating the dataset\n",
    "\n",
    "all_sets = [X_train,y_train,X_validation,y_validation,X_test,y_test]\n",
    "all_sets_names = [\"Training set\",\"Training targtets\",\"Validation set\",\"Validation targets\",\"Test set\",\"Test targets\"]\n",
    "features = [\"MedInc\",\"HouseAge\",\"AveRooms\",\"AveBdrms\",\"Population\",\"AveOccup\",\"Latidue\",\"Longitude\"]\n",
    "\n",
    "#Normalizing data\n",
    "for i,set in enumerate(all_sets[0::2]):\n",
    "    for col in range(len(features)):\n",
    "        norm_feature = normalize(np.reshape(set[:,col],(1,len(set[:,col]))))\n",
    "        all_sets[i*2][:,col] = norm_feature\n",
    "#TODO: why do the distributions not look different?\n",
    "\n",
    "#Checking the data, to see what would be good to normalize\n",
    "for set, name in zip(all_sets[0::2],all_sets_names[0::2]):\n",
    "    \n",
    "    print('\\033[4m'+'\\033[1m'+f\"{name}\"+'\\033[0m'+'\\033[0m')\n",
    "    print(f\"size: {str(set.shape) : >10}\")\n",
    "    stats = {\"mean\":[],\n",
    "             \"std\":[],\n",
    "             \"min\":[],\n",
    "             \"max\":[]}\n",
    "    fig,axs = plt.subplots(2,len(features)//2,figsize=(8,4),layout = \"tight\")\n",
    "    for col,feature in enumerate(features):\n",
    "        feature_data = set[:,col]\n",
    "        stats[\"mean\"].append(np.mean(feature_data))\n",
    "        stats[\"std\"].append(np.std(feature_data))\n",
    "        stats[\"min\"].append(np.min(feature_data))\n",
    "        stats[\"max\"].append(np.max(feature_data))\n",
    "        axs[int(np.floor(col/4))][(col%4)].hist(feature_data,bins=50)\n",
    "        axs[int(np.floor(col/4))][(col%4)].set_title(feature)\n",
    "\n",
    "    print('\\033[1m'+\"          \"+f\"{'   '.join(features)}\"+'\\033[0m')\n",
    "    for stat,vals in stats.items():\n",
    "        x = [str(round(val,2)) for val in vals]\n",
    "        print('{:>4}{:>12s}{:>11s}{:>11s}{:>11s}{:>12s}{:>12s}{:>11s}{:>11s}'.format(stat,x[0],x[1],x[2],x[3],x[4],x[5],x[6],x[7]))\n",
    "    \n",
    "    \n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "c = np.linspace(10,20,10)*1-9\n",
    "Z = -1j/(2*np.pi*5.4e9*c)+37.5\n",
    "Z = 50*50/Z\n",
    "plt.figure()\n",
    "plt.plot(np.real(Z),np.imag(Z),'or')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Networks"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T19:39:14.746834Z",
     "start_time": "2024-11-09T19:39:14.706270Z"
    }
   },
   "source": [
    "from models import NeuralNet_deep, NeuralNet_wide, NeuralNet_default, NeuralNet_deep_wider, NeuralNet_deeper_wide\n",
    "\n",
    "def train_model(model, optimizer, train_loader, val_loader, device, num_epochs=5):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print('-'*20, f'Epoch {epoch}', '-'*20)\n",
    "        # Train one epoch\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predict = model(data)\n",
    "            loss = loss_fn(predict, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        print(f'Train Epoch {epoch} | Average Training Loss {np.mean(train_losses[-len(train_loader):])}')\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        # correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                predict = model(data)\n",
    "                val_loss += F.mse_loss(predict, target, reduction='sum').item()  # sum up batch loss\n",
    "                # correct += (predict == target).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        # avg_correct = correct / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        # val_accuracies.append(avg_correct)\n",
    "\n",
    "        print(f'Validation set: Average loss: {val_loss:.4f}, Accuracy: {0}/{len(val_loader.dataset)} ({100. * 0:.0f}%)\\n')\n",
    "    \n",
    "    return train_losses, val_losses, val_accuracies\n"
   ],
   "outputs": [],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
